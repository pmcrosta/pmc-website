[
  {
    "objectID": "research/building_a_dataset.html",
    "href": "research/building_a_dataset.html",
    "title": "Building a dataset",
    "section": "",
    "text": "To gain a better understanding of the current state of education in Fair Haven, I started by building a data set. This document shares the process I went through to combine state and federal resources to generate data sets that ultimately would enable the following:\n\nCreation of a set of suitable comparison school districts for Fair Haven\nAn analysis of student outcomes, educational inputs, and their relationship over time\n\nIn an effort to be as transparent as possible, this document will contain descriptions of source and derived data sets as well as code in the R programming language that one can use to reproduce results.\n\n\nCode - Load libraries\noptions(width = 120)\n\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(googlesheets4)\nlibrary(googledrive)\nlibrary(haven)\nlibrary(cluster)\nlibrary(MASS)\nlibrary(ggpmisc)\nlibrary(ggrepel)\nlibrary(ggfortify)\nlibrary(glue)\nlibrary(DT)\nlibrary(htmltools)\nlibrary(factoextra)\n\nset.seed(2024)\n\n# Commonly used State ID numbers (staid) and Federal Local Education Authority (LEA) IDs\n# for FH, Little Silver, Rumson, and Shrewsbury\nfh_leaid &lt;- \"3404950\"\nfh_staid &lt;- \"NJ-251440\"\n\nls_leaid &lt;- \"3408790\"\nls_staid &lt;- \"NJ-252720\"\n\nrums_leaid &lt;- \"3414370\"\nrums_staid &lt;- \"NJ-254570\"\n\nshrews_leaid &lt;- \"3414970\"\nshrews_staid &lt;- \"NJ-254770\""
  },
  {
    "objectID": "research/building_a_dataset.html#approaches",
    "href": "research/building_a_dataset.html#approaches",
    "title": "Building a dataset",
    "section": "Approaches",
    "text": "Approaches\nI leverage a number of techniques to generate peer districts for Fair Haven using these data. This exercise is both an art and science, as it is both grounded in data and subject to a number of researcher choices. To that end, a few sets of comparison districts will be created. Note that the final comparison data sets will be filtered to only include PK-8 districts like Fair Haven; this will happen later though since it requires yet another data source. In addition, the following section is not a “full academic” treatment of these approaches, meaning that the primary end is to be useful, not necessarily to fully account for all methodological nuances. However, I will compare district characteristics across various peer sets.\n\nEuclidean distance\nOne simple, albeit somewhat naive, approach to identifying peer districts is to find the districts that are “closest” to each other given the district characteristics that were identified above. To do this, I\n\nStandardize all of our variables\nCompute a distance matrix (Euclidean distance in multidimensional space)\nRank districts in terms of their “proximity” to Fair Haven\n\nOne downside to this strategy is that there are a number of highly correlated variables in the data set, and the distance matrix may overweight importance of these characteristics. For example, there are a number of income-based measures, and thus this approach may over-index on the household incomes of district residents. However, it may also produce a reasonable peer set.\n\n\nCode - Using Euclidean distance\n# Standardize variables\nedge_df_scale &lt;- scale(edge_df[,-c(1:3)])\nrownames(edge_df_scale) &lt;- edge_df$LEAID\n\n## compute the distance matrix\nedge_dist &lt;- dist(edge_df_scale, method = \"euclidean\")\n\n# Find the indices of the closest districts\nclosest_indices_euclid &lt;- order(as.matrix(edge_dist)[, which(attr(edge_dist, \"Labels\")==fh_leaid)])\n\n# Reorder edge_df so the most similar districts are on top\nsimilar_districts_euclid &lt;- edge_df[closest_indices_euclid, ] %&gt;% dplyr::mutate(euclid_score=1:n()) %&gt;% dplyr::select(LEAID, Geography, euclid_score)\n\n# Print table\ndatatable(similar_districts_euclid,\n  options = list(\n    pageLength = 5,\n    searching = TRUE,\n    ordering = TRUE\n  ),\n  rownames = FALSE,\n  caption = tags$caption(\n    style = \"caption-side: top; text-align: center;\",\n    \"Most similar districts by Euclidean distance\")\n)\n\n\n\n\n\n\n\n\nMahalanobis distance\nA second smiple distance-based approach is to use the Mahalanobis distance, as it is capable of taking into coniderations the correlations present in the data set. To do this, I\n\nStandardize all of our variables\nCompute a distance matrix (Mahalanobis pairwise distances)\nRank districts in terms of their “proximity” to Fair Haven\n\n\n\nCode - Using Mahalanobis distance\n# Standardize variables\nedge_df_scale &lt;- scale(edge_df[,-c(1:3)])\nrownames(edge_df_scale) &lt;- edge_df$LEAID\n\nmahalanobis_dist_matrix &lt;- function(data) {\n  cov_matrix &lt;- cov(data)\n  n &lt;- nrow(data)\n  dist_matrix &lt;- matrix(0, nrow = n, ncol = n)\n\n  for (i in 1:n) {\n    for (j in 1:n) {\n      dist_matrix[i, j] &lt;- mahalanobis(data[i, ], data[j, ], cov_matrix)\n    }\n  }\n  return(dist_matrix)\n}\n\n## compute the distance matrix\ndist_mat_mah &lt;- mahalanobis_dist_matrix(na.omit(edge_df_scale))\nrownames(dist_mat_mah) &lt;- dimnames(na.omit(edge_df_scale))[[1]]\n\n# Find the indices of the closest districts\nclosest_indices_mah &lt;- order(as.matrix(dist_mat_mah)[, which(rownames(dist_mat_mah)==fh_leaid)])\n\n# Print the most similar districts\nsimilar_districts_mah &lt;- (edge_df %&gt;% dplyr::filter(LEAID %in% rownames(dist_mat_mah))) [closest_indices_mah, ] %&gt;% dplyr::mutate(mah_score=1:n()) %&gt;% dplyr::select(LEAID, Geography, mah_score)\n\n# Print table\ndatatable(similar_districts_mah,\n  options = list(\n    pageLength = 5,\n    searching = TRUE,\n    ordering = TRUE\n  ),\n  rownames = FALSE,\n  caption = tags$caption(\n    style = \"caption-side: top; text-align: center;\",\n    \"Most similar districts by Mahalanobis distance\")\n)\n\n\n\n\n\n\n\n\nPrincipal Components\nAnother strategy for identifying peer districts is a dimensionality reduction technique called Principal Components Analysis. This is actually the same technique used to develop the original District Factor Groups. Though here I am using more data and more recent data. The central idea is to reduce our 40-dimensional (40-column) data set into a smaller set of components (or dimensions) that are maximally different from each other and uncorrelated with each other. These new components would contain the essence of the larger set of columns. As in the DFG calculation, I expect the first principal component to contain the variance associated with socioeconomic status (SES).\nThe general procedure is to:\n\nCompute the principal components on the data set\nAssess which dimensions load in which principal components\nRank order component of interest, and find districts surrounding Fair Haven\n\nIf the first one or two components is not sufficient, we are in clustering territory, which will be addressed later.\n\n\nCode - Using Principal Components\n# Perform PCA\npcadat &lt;- na.omit(edge_df[,-c(1:3)])\nrownames(pcadat) &lt;- make.unique(na.omit(edge_df)$Geography)\npca_result &lt;- prcomp(pcadat, scale.=T, center = T)\n\n#round(pca_result$sdev^2/sum(pca_result$sdev^2), 2) #first two ~49% variance, 37+12\n\n# Extract principal components\npc_all_scores &lt;- pca_result$x\n\n#Visualize the reduced data\n#autoplot(pca_result, data = pcadat, label = TRUE, label.size = 3)\n\n# Get loadings\npca_loadings &lt;- pca_result$rotation\n\n# Transform loadings into a long format data frame\nloadings_df &lt;- as.data.frame(pca_loadings)\nloadings_df$Variable &lt;- rownames(pca_loadings)\nloadings_long &lt;- reshape2::melt(loadings_df, id.vars = \"Variable\", variable.name = \"PC\", value.name = \"Loading\")\n\n\nIn Figure 1, it is clear that Component 1 (PC1) is loading on income and education dimensions, which are qualitatively aligned with SES. However, Component 2 (PC2) is loading on other potentially relevant dimensions, such as family size and the population under 18. Note the differences below in the districts that surround Fair Haven for both PC1 and PC2.\n\nPCA HeatmapPC1 PeersPC2 Peers\n\n\n\n\nCode\n# Create heatmap\nggplot(loadings_long %&gt;% filter(PC %in% c(\"PC1\", \"PC2\")), aes(x = PC, y = Variable, fill = Loading)) +\n  geom_tile() +\n  scale_fill_gradient2(low = \"blue\", mid = \"white\", high = \"orange\") +\n  theme_minimal() +\n  labs(title = \"PCA Loadings\", x=\"\", y=\"\")\n\n\n\n\n\n\n\n\nFigure 1: Loadings from first two components of the PCA.\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\nClustering\nA final approach to identifying peer districts is cluster analysis. Cluster analysis leverages distance functions to separate districts based on similarity, with the goal of creating groups of high similarity within clusters and high dissimilarity between clusters. I will explore both K-means and hierarchical clustering techniques, looking at a few examples of each.\n\nK-means clusters\nK-means clustering requires a distance matrix as input, and we have already created Euclidean and Mahalanobis distance matrices. We can also apply distance calculations to the PCA results in order to generate clusters based on the reduced dimensionality provided by principal components. Both scaled and un-scaled PCA results are clustered. The un-scaled version should over-weight PC1, and the scaled version should treat PC1 and PC2 more equally. The tabs below show the resulting peer groups from a standard K-means routine that assumes 10 clusters (a full treatment of K-means that searches for the optimal number of clusters is omitted in this document). Each tab includes a list of districts that were clustered alongside Fair Haven given the particular distance matrix as input.\n\n\nCode - K-means clustering\n## distance matrix from earlier\n# Euclidean: edge_dist (557)\n# Mahalanobis: dist_mat_mah (555)\n# PCA: pc_all_scores (needs dist, scaled and unscaled) (555)\n\n# Scale the principal component scores\nscaled_pc_scores &lt;- scale(pc_all_scores[,c(1:2)])\npc_dist_scaled &lt;- dist(scaled_pc_scores)\npc_dist_unscaled &lt;- dist(pc_all_scores[,c(1:2)])\n\n# Apply k-means\nkm_pc_scaled &lt;- kmeans(pc_dist_scaled, centers = 10)\nkm_pc_unscaled &lt;- kmeans(pc_dist_unscaled, centers = 10)\nkm_euclid &lt;- kmeans(edge_dist, centers = 10)\nkm_maha &lt;- kmeans(dist_mat_mah, centers = 10)\n\n# Access cluster assignments\nclusters_pc_scaled &lt;- km_pc_scaled$cluster\nclusters_pc_unscaled &lt;- km_pc_unscaled$cluster\nclusters_euclid &lt;- km_euclid$cluster\nclusters_maha &lt;- km_maha$cluster\n\nfh_pc_scaled &lt;- clusters_pc_scaled[\"Fair Haven Borough School District, NJ\"]\nfh_pc_unscaled &lt;- clusters_pc_unscaled[\"Fair Haven Borough School District, NJ\"]\nfh_euclid &lt;- clusters_euclid[fh_leaid]\nfh_maha &lt;- clusters_maha[fh_leaid]\n\nmat_pc_scaled &lt;- as_tibble(names(clusters_pc_scaled[clusters_pc_scaled==fh_pc_scaled])) %&gt;% rename(\"PC Scaled\"=value)\nmat_pc_unscaled &lt;- as_tibble(names(clusters_pc_unscaled[clusters_pc_unscaled==fh_pc_unscaled]))  %&gt;% rename(\"PC Unscaled\"=value)\nmat_euclid &lt;- as_tibble(names(clusters_euclid[clusters_euclid==fh_euclid]))  %&gt;% rename(\"Euclidean\"=value) %&gt;%\n  dplyr::left_join(edge_df %&gt;% dplyr::select(Geography, LEAID) %&gt;% mutate(LEAID=as.character(LEAID)), by = c(\"Euclidean\"=\"LEAID\"))\nmat_maha &lt;- as_tibble(names(clusters_maha[clusters_maha==fh_maha]))  %&gt;% rename(\"Mahalanobis\"=value) %&gt;%\n  dplyr::left_join(edge_df %&gt;% dplyr::select(Geography, LEAID) %&gt;% mutate(LEAID=as.character(LEAID)), by = c(\"Mahalanobis\"=\"LEAID\"))\n\n\n\nEuclideanMahalanobisPC ScaledPC Unscaled\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\nHierarchical\nAnother clustering strategy is called Hierarchical Clustering, which generates a full tree of districts based on similarity. One advantage of this technique is that one does not have to determine a priori how many clusters there are in the data. The tree can be cut at any level in order to find clusters of appropriate size.\nAs with K-means, the input to the hierarchical clustering routine is a distance matrix. There is another parameter included in the model to instruct how the clustering algorithm should combine districts with each other and with groups. This is often called the “method”, and here will explore a few methods. Again as with K-means, a full treatment of cluster analysis is not provided here. Rather, this exercise is to generate candidate sets of peers that will be qualitatively assessed in the next section.\nThe first tab below shows a partial dendrogram highlighting part of the full tree that contains a decent-sized cluster around Fair Haven. The other two tabs show the resulting peer groups from different clustering inputs.\n\n\nCode - Hierarchical clustering\nfind_min_cluster &lt;- function(hc, target_observation = \"Fair Haven Borough\", min_size = 50, verbose=FALSE) {\n  # Function to find where to cut tree to generate smallest cluster with FH that has at least 50 districts\n  n &lt;- length(hc$labels)\n  min_k &lt;- NULL\n  min_cluster_size &lt;- Inf \n\n  for (k in 2:n) {\n    clusters &lt;- cutree(hc, k = k)\n    target_cluster &lt;- clusters[names(clusters) == target_observation]\n    cluster_members &lt;- names(clusters[clusters == target_cluster])\n    cluster_size &lt;- length(cluster_members)\n\n    if (cluster_size &gt;= min_size && cluster_size &lt; min_cluster_size) {\n      min_k &lt;- k\n      min_cluster_size &lt;- cluster_size\n    }\n  }\n\n  final_clusters &lt;- cutree(hc, k = min_k)\n  \n  \n  if (!is.null(final_clusters)) {\n    \n    # Check the size of the cluster that \"Fair Haven Borough\" belongs to.\n    target_cluster &lt;- final_clusters[names(final_clusters) == target_observation]\n    cluster_members &lt;- names(final_clusters[final_clusters == target_cluster]) # contains peers\n    if (verbose) {\n      print(paste(\"Size of cluster containing Fair Haven Borough:\", length(cluster_members)))\n      print(paste(\"Number of Clusters:\", length(unique(final_clusters))))\n    }\n  } else {\n    if (verbose) print(\"No cluster found with size &gt;= 50 containing Fair Haven Borough.\")\n  }\n\n  \n  if (!is.null(min_k)) {\n    return(list(final_clusters=final_clusters, target_cluster=target_cluster, cluster_members=cluster_members))\n  } else {\n    return(NULL)\n  }\n}\n\n# Distance matrices:\n#   pc_dist_scaled\n#   pc_dist_unscaled\n#   edge_dist\n#   dist_mat_mah (SKIP_)\n\n# Hierarchical clustering using Ward and WPGMA Linkage\n\n## Euclidean\nhc_euclid_ward &lt;- hclust(edge_dist, method = \"ward.D2\" )\nhc_euclid_mcquitty &lt;- hclust(edge_dist, method=\"mcquitty\")\n\nhc_euclid_ward_clusters &lt;- find_min_cluster(hc_euclid_ward, min_size = 50, target_observation = fh_leaid)\nhc_euclid_mcquitty_clusters &lt;- find_min_cluster(hc_euclid_mcquitty, min_size = 50, target_observation = fh_leaid)\n\n## PC scaled\nhc_pc_dist_scaled_ward &lt;- hclust(pc_dist_scaled, method = \"ward.D2\" )\nhc_pc_dist_scaled_mcquitty &lt;- hclust(pc_dist_scaled, method=\"mcquitty\")\n\nhc_pc_dist_scaled_ward_clusters &lt;- find_min_cluster(hc_pc_dist_scaled_ward, min_size = 50, target_observation = \"Fair Haven Borough School District, NJ\")\nhc_pc_dist_scaled_mcquitty_clusters &lt;- find_min_cluster(hc_pc_dist_scaled_mcquitty, min_size = 50, target_observation = \"Fair Haven Borough School District, NJ\")\n\n## PC unscaled\nhc_pc_dist_unscaled_ward &lt;- hclust(pc_dist_unscaled, method = \"ward.D2\" )\nhc_pc_dist_unscaled_mcquitty &lt;- hclust(pc_dist_unscaled, method=\"mcquitty\")\n\nhc_pc_dist_unscaled_ward_clusters &lt;- find_min_cluster(hc_pc_dist_unscaled_ward, min_size = 50, target_observation = \"Fair Haven Borough School District, NJ\")\nhc_pc_dist_unscaled_mcquitty_clusters &lt;- find_min_cluster(hc_pc_dist_unscaled_mcquitty, min_size = 40, target_observation = \"Fair Haven Borough School District, NJ\")\n\n# Create cluster indicators \nedge_df &lt;- edge_df %&gt;% \n  dplyr::mutate(\n    hc_euclid_ward = LEAID %in% hc_euclid_ward_clusters$cluster_members,\n    hc_euclid_mcquitty = LEAID %in% hc_euclid_mcquitty_clusters$cluster_members,\n    hc_pc_dist_scaled_ward = Geography %in% hc_pc_dist_scaled_ward_clusters$cluster_members,\n    hc_pc_dist_scaled_mcquitty = Geography %in% hc_pc_dist_scaled_mcquitty_clusters$cluster_members,\n    hc_pc_dist_unscaled_ward = Geography %in% hc_pc_dist_unscaled_ward_clusters$cluster_members,\n    hc_pc_dist_unscaled_mcquitty = Geography %in% hc_pc_dist_unscaled_mcquitty_clusters$cluster_members,\n    LEAID = as.character(LEAID)\n    )\n\nccdnjk12 &lt;- ccdnjk12 %&gt;% \n  dplyr::left_join(edge_df, by = \"LEAID\")\n\n\n\nDendrogramEuclidean Ward PeersPC Unscaled Ward Peers\n\n\n\n\nCode\n# visualize the tree\n# fviz_dend(hc_euclid_ward, k = 4, color_labels_by_k = TRUE, cex=.1, type=\"circular\")\n\nviztree &lt;- function(datain, members, distfun, clustfun) {\n  datain &lt;- datain %&gt;%\n    dplyr::filter(LEAID %in% members)\n  \n  datain_scale &lt;- scale(datain[,-c(1:3)])\n  rownames(datain_scale) &lt;- datain$LEAID\n\n  datain_dist &lt;- dist(datain_scale, method = distfun)\n  \n  newclust &lt;- hclust(datain_dist, method = \"ward.D2\" )\n  newclust$labels &lt;- gsub(\" School District, NJ\", \"\", datain$Geography)\n  \n  fviz_dend(newclust, cex=.4, horiz=T)\n}\n\nviztree(edge_df, hc_euclid_ward_clusters$cluster_members, \"euclidean\", \"ward.D2\")\n\n\n\n\n\n\n\n\nFigure 2: Partial dendrogram from Ward clustering (Euclidean)\n\n\n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\nComparing Peer Sets"
  },
  {
    "objectID": "research/building_a_dataset.html#comparing-peer-sets",
    "href": "research/building_a_dataset.html#comparing-peer-sets",
    "title": "Building a dataset",
    "section": "Comparing Peer Sets",
    "text": "Comparing Peer Sets"
  },
  {
    "objectID": "issues.html",
    "href": "issues.html",
    "title": "Issues",
    "section": "",
    "text": "My commitment is to address the key issues facing our schools with thoughtful consideration and a focus on what’s best for our students."
  },
  {
    "objectID": "issues.html#fiscal-responsibility",
    "href": "issues.html#fiscal-responsibility",
    "title": "Issues",
    "section": "Fiscal Responsibility",
    "text": "Fiscal Responsibility\nOur district faces significant budget challenges, and we must approach them with transparency and data-driven decision-making. My experience in research and data analysis will be invaluable in ensuring that every dollar spent directly benefits our students’ educational experience. We will prioritize maintaining essential programs and personnel, while exploring innovative solutions to optimize resource allocation and improve operational efficiencies. We must be thoughtful stewards of taxpayer dollars, focusing on long-term sustainability and the highest return on educational investment. I will work to ensure that any necessary cuts are made strategically, minimizing impact on student learning and maximizing equitable access to educational opportunities."
  },
  {
    "objectID": "issues.html#improving-communication-and-transparency",
    "href": "issues.html#improving-communication-and-transparency",
    "title": "Issues",
    "section": "Improving Communication and Transparency",
    "text": "Improving Communication and Transparency\nEffective communication and transparency are vital for a strong school community. I will advocate for proactive, open dialogue between the Board, administration, teachers, parents, and students. We need to establish clear, accessible channels for sharing information about district policies, budget decisions, and academic progress. I will work to ensure that Board meetings are informative and accessible, and that community feedback is actively sought and valued. Building trust through clear and consistent communication is essential for fostering a collaborative and supportive learning environment."
  },
  {
    "objectID": "issues.html#academic-statement",
    "href": "issues.html#academic-statement",
    "title": "Issues",
    "section": "Academic Statement",
    "text": "Academic Statement\nOur academic focus must be on providing a rigorous, well-rounded education that prepares all students for success in high school and beyond. I am committed to a curriculum that emphasizes critical thinking, problem-solving, and a deep understanding of core subjects. I will support the district’s efforts to align curriculum from Kindergarten through 8th grade, focusing on evidence-based practices and data-driven improvements. I will champion the articulation of curriculum and expectations with Rumson and RFH, ensuring a seamless transition for our students. Furthermore, I will prioritize professional development for our teachers, enabling them to provide differentiated instruction and support all learners, including mid-tier students and those with unique needs. We must foster a culture of continuous improvement, driven by data and a commitment to excellence."
  },
  {
    "objectID": "issues.html#extracurricular-statement",
    "href": "issues.html#extracurricular-statement",
    "title": "Issues",
    "section": "Extracurricular Statement",
    "text": "Extracurricular Statement\nExtracurricular activities and a positive school climate are essential for the social, emotional, and behavioral development of our students. I believe in fostering an inclusive environment that supports the whole child, promoting well-being and a sense of belonging. I will advocate for programs that encourage teamwork, leadership, and personal growth, ensuring that all students have opportunities to participate and thrive. We must prioritize the health, wellness, and safety of our students, providing resources and support to address their social and emotional needs.\n\n\n\n\n\n\n\nTip\n\n\n\nElection day is Tuesday, November 5, 2025."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "We moved to Fair Haven in early 2021 during the Pandemic in search of a family-oriented community down the shore with excellent schools and in commuting distance to NYC. Fair Haven certainly fit the bill. Fast forward a few years and we are fully integrated into the FH community, with a first grader and pre-K-er both at Sickles.\nProfessionally, I spent the first half of my career working in education and related industries. During college, I worked as a research assistant at the Cornell Higher Education Research Institute (CHERI) studying determinants of faculty productivity. Shortly after, I spent a year at a policy evaluation firm measuring the impacts of federally funded early childhood centers. I then entered graduate school at Teachers College, Columbia University to pursue a degree in economics and education while working at the Community College Research Center (CCRC). A few years in, I decided that I needed some more grounded experience, and took two years off to be a mathematics and statistics teacher at a growing American school in Cancún, Mexico. I eventually returned to New York City and Columbia to finish graduate school before venturing out into the world of EdTech, where I worked as a researcher and data scientist at several startups. I’ve since left the education world professionally, but am still focused on research, data, and decision-making as a quantitative user experience researcher at a global technology company.\nAs I have been following the current Fair Haven district budget situation, and thinking about the long-term investments that me and my family are making in the community, it seemed like a natural next step to get more involved and to contribute a data-drive, outcome-oriented voice to these important issues facing our community and schools. It’s almost as if I have been preparing my whole life for this opportunity, and I am excited to get started.\nFor more info, check out my resume or Google Scholar profile."
  },
  {
    "objectID": "about.html#background-and-why-im-running",
    "href": "about.html#background-and-why-im-running",
    "title": "About",
    "section": "",
    "text": "We moved to Fair Haven in early 2021 during the Pandemic in search of a family-oriented community down the shore with excellent schools and in commuting distance to NYC. Fair Haven certainly fit the bill. Fast forward a few years and we are fully integrated into the FH community, with a first grader and pre-K-er both at Sickles.\nProfessionally, I spent the first half of my career working in education and related industries. During college, I worked as a research assistant at the Cornell Higher Education Research Institute (CHERI) studying determinants of faculty productivity. Shortly after, I spent a year at a policy evaluation firm measuring the impacts of federally funded early childhood centers. I then entered graduate school at Teachers College, Columbia University to pursue a degree in economics and education while working at the Community College Research Center (CCRC). A few years in, I decided that I needed some more grounded experience, and took two years off to be a mathematics and statistics teacher at a growing American school in Cancún, Mexico. I eventually returned to New York City and Columbia to finish graduate school before venturing out into the world of EdTech, where I worked as a researcher and data scientist at several startups. I’ve since left the education world professionally, but am still focused on research, data, and decision-making as a quantitative user experience researcher at a global technology company.\nAs I have been following the current Fair Haven district budget situation, and thinking about the long-term investments that me and my family are making in the community, it seemed like a natural next step to get more involved and to contribute a data-drive, outcome-oriented voice to these important issues facing our community and schools. It’s almost as if I have been preparing my whole life for this opportunity, and I am excited to get started.\nFor more info, check out my resume or Google Scholar profile."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Peter M. Crosta",
    "section": "",
    "text": "Welcome to my campaign website! I’m Peter M. Crosta, and I’m running for the Fair Haven Board of Education in 2025 because I believe in a data-driven, outcome-oriented approach to ensuring the best possible education for all Fair Haven students.\n[photo coming!]\nBorn and raised in New Jersey, I spent formative summers on the Bayshore before making Fair Haven home in 2021 with my wife, Sarah, and our two children (ages 4 and 7) who are currently enrolled at Sickles Elementary School. I have expertise in educational evaluation and policy analysis, having earned a PhD in economics of education from Columbia University, and I spent a decade conducting research on higher-ed institutions serving diverse student populations. My vision for Fair Haven schools is to ensure every child has access to a high-quality education that prepares them for success in a rapidly-changing world. My research has given me a deep understanding of resource allocation challenges in educational settings, which will be invaluable in addressing Fair Haven’s budget constraints and ensuring all students have the support they need. Beyond my professional experience, I also volunteer on the board of Fair Haven Rec Soccer. When not enjoying the beach with my family or watching the kids play soccer at Fair Haven fields, I work as a user experience researcher for a global technology company."
  },
  {
    "objectID": "research.html",
    "href": "research.html",
    "title": "Research and Analysis",
    "section": "",
    "text": "As part of my commitment to being data-driven and outcome-oriented, I’ll share examples of research, data analysis, and related insights on this page.\nTODO:\n\nBuilding a dataset\nEnrollments\nStandardized Test Scores\nInputs"
  }
]